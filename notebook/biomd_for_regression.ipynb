{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592e54d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13651, 3790)\n"
     ]
    }
   ],
   "source": [
    "# Test all testable biomodels (i.e., models with existing annotation)\n",
    "import libsbml\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "PROJ_DIR = \"/Users/woosubs/Desktop/AutomateAnnotation/AnnotationRecommender/\"\n",
    "MOD_DIR = os.path.join(PROJ_DIR, \"annotation_recommender\")\n",
    "sys.path.append(MOD_DIR)\n",
    "\n",
    "BIOMD_12 = 'BIOMD0000000012.xml'\n",
    "BASE_DIR = '/Users/woosubs/Desktop/AutomateAnnotation/'\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"DATA\")\n",
    "ALGO_DIR = os.path.join(DATA_DIR, \"algo\")\n",
    "CHEBI_DIR = os.path.join(DATA_DIR, \"chebi\")\n",
    "RHEA_DIR = os.path.join(DATA_DIR, \"rhea\")\n",
    "BIOMODEL_DIR = os.path.join(DATA_DIR, \"biomodels/curated_biomodels_31mar2021\")\n",
    "BIGG_DIR = '/Users/woosubs/Desktop/AutomateAnnotation/DATA/bigg'\n",
    "ecoli_fpath = os.path.join(BIGG_DIR, \"e_coli_core.xml\")\n",
    "\n",
    "\n",
    "from annotation_recommender import species_annotation as sa\n",
    "from annotation_recommender import reaction_annotation as ra\n",
    "from annotation_recommender import constants as cn\n",
    "from annotation_recommender import iterator as it\n",
    "from annotation_recommender import tools\n",
    "\n",
    "# chebi to shortened formula\n",
    "with open(os.path.join(CHEBI_DIR, 'chebi_shortened_formula_30apr2022.pickle'), 'rb') as f:\n",
    "  ref_shortened_chebi_to_formula = pickle.load(f)\n",
    "# shortened formula to chebi\n",
    "with open(os.path.join(CHEBI_DIR, 'shortened_formula_to_chebis_20jul2022.pickle'), 'rb') as f:\n",
    "  ref_shortened_formula_to_chebi = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(CHEBI_DIR, 'chebi_synonyms.pickle'), 'rb') as f:\n",
    "  chebi_synonyms = pickle.load(f)\n",
    "chebi_low_synonyms = dict()\n",
    "for one_k in chebi_synonyms.keys():\n",
    "  chebi_low_synonyms[one_k] = list(set([val.lower() for val in chebi_synonyms[one_k]]))\n",
    "\n",
    "with open(os.path.join(RHEA_DIR, 'kegg2rhea_master.pickle'), 'rb') as handle:\n",
    "  ref_kegg2rhea_master = pickle.load(handle)\n",
    "with open(os.path.join(RHEA_DIR, 'kegg2rhea_bi.pickle'), 'rb') as handle:\n",
    "  ref_kegg2rhea_bi = pickle.load(handle)\n",
    "\n",
    "# mapping rhea terms to BI\n",
    "with open(os.path.join(RHEA_DIR, 'rhea_all2bi.pkl'), 'rb') as handle:\n",
    "  ref_rhea2bi = pickle.load(handle)\n",
    "\n",
    "# load reference matrix\n",
    "with open(os.path.join(ALGO_DIR, 'binary_ref_df.pickle'), 'rb') as handle:\n",
    "    ref_mat = pickle.load(handle)\n",
    "# check its shape\n",
    "print(ref_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ab314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'eckegg2rhea.pickle'), 'rb') as handle:\n",
    "  eckegg2rhea = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae222c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eckegg2rhea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886410d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188\n"
     ]
    }
   ],
   "source": [
    "# collect all reactions\n",
    "all_reactions_to_test = 0\n",
    "for one_biomd in eckegg2rhea.keys():\n",
    "  one_model_reactions = eckegg2rhea[one_biomd]\n",
    "  all_reactions_to_test += len(one_model_reactions)\n",
    "print(all_reactions_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c25c57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_mat = ra.ref_mat.dot(reaction_an.query_df)\n",
    "maxes = multi_mat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f2f634d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxes['HXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1feba50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 0\n",
      "We are at 10\n"
     ]
    }
   ],
   "source": [
    "## Testing individual reactions\n",
    "reac_res_df = pd.DataFrame(0,\n",
    "                      index=range(all_reactions_to_test),\n",
    "                      columns = ['model', 'reaction_id', 'num_candidates',\n",
    "                                 'max_match', 'mean_match_score', 'var_match_score',\n",
    "                                 'accuracy'])\n",
    "count = 0\n",
    "for idx, one_biomd in enumerate(list(eckegg2rhea.keys())):\n",
    "  if idx % 10 == 0:\n",
    "    print(\"We are at\", idx)\n",
    "  one_biomd_fpath = os.path.join(BIOMODEL_DIR, one_biomd)\n",
    "  species_an = sa.SpeciesAnnotation(libsbml_fpath=one_biomd_fpath)\n",
    "  reaction_an = ra.ReactionAnnotation(libsbml_fpath=one_biomd_fpath)\n",
    "  pred_species = species_an.predictAnnotationByName()\n",
    "  pred_reaction = reaction_an.predictAnnotation(inp_spec_dict=species_an.formula)\n",
    "  multi_mat = ra.ref_mat.dot(reaction_an.query_df)\n",
    "  maxes = multi_mat.max()\n",
    "  res = it.iterateAndGetUpdatedResults(spec_cl=species_an,\n",
    "                                       reac_cl=reaction_an,\n",
    "                                       num_iter=5,\n",
    "                                       show_message=False)\n",
    "  # reference..\n",
    "  one_model_ref = eckegg2rhea[one_biomd]\n",
    "  for one_r in one_model_ref.keys():\n",
    "    existing_annotation = [ref_rhea2bi[val] for val in one_model_ref[one_r] if \\\n",
    "                           val in ref_rhea2bi.keys()]\n",
    "    if any([val in res['candidates'][one_r] for val in existing_annotation]):\n",
    "      is_accurate = 1\n",
    "    else:\n",
    "      is_accurate = 0\n",
    "    reac_res_df.loc[count, 'model'] = one_biomd\n",
    "    reac_res_df.loc[count, 'reaction_id'] = one_r           \n",
    "    reac_res_df.loc[count, 'num_candidates'] = len(reaction_an.candidates[one_r])\n",
    "    reac_res_df.loc[count, 'max_match'] = maxes[one_r]\n",
    "    match_score_dict = reaction_an.match_score[one_r]\n",
    "    match_score_list = [match_score_dict[val] for val in match_score_dict.keys()]\n",
    "    reac_res_df.loc[count, 'mean_match_score'] = np.mean(match_score_list)\n",
    "    reac_res_df.loc[count, 'var_match_score'] = np.var(match_score_list)\n",
    "    reac_res_df.loc[count, 'accuracy'] = is_accurate\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reac_res_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a1dc90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reac_res_df.to_csv('individual_reaction_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ebc18dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(reac_res_df['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daa9dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, do the same thing for CHEBI; \n",
    "with open(os.path.join(os.getcwd(), 'chebi_models.pickle'), 'rb') as handle:\n",
    "  chebi_models = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d9222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902\n"
     ]
    }
   ],
   "source": [
    "# collect all species\n",
    "all_species_to_test = 0\n",
    "for one_biomd in chebi_models.keys():\n",
    "  one_model_species = chebi_models[one_biomd]\n",
    "  all_species_to_test += len(one_model_species)\n",
    "print(all_species_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0525ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 0\n",
      "We are at 30\n",
      "We are at 60\n",
      "We are at 90\n",
      "We are at 120\n",
      "We are at 150\n",
      "We are at 180\n",
      "We are at 210\n",
      "We are at 240\n",
      "We are at 270\n",
      "We are at 300\n"
     ]
    }
   ],
   "source": [
    "spec_res_df = pd.DataFrame(0,\n",
    "                           index=range(all_species_to_test),\n",
    "                           columns = ['model', 'species_id', 'name_used', 'name_length', \n",
    "                                      'num_candidates', 'match_score', 'accuracy'])\n",
    "\n",
    "count = 0\n",
    "for idx, one_biomd in enumerate(list(chebi_models.keys())):\n",
    "  if idx % 30 == 0:\n",
    "    print(\"We are at\", idx)\n",
    "  model_itm = chebi_models[one_biomd]\n",
    "  one_biomd_fpath = os.path.join(BIOMODEL_DIR, one_biomd)\n",
    "  species_an = sa.SpeciesAnnotation(libsbml_fpath=one_biomd_fpath)\n",
    "  pred_species = species_an.predictAnnotationByName(inp_spec_list=list(model_itm.keys()))\n",
    "  for one_spec in model_itm.keys(): \n",
    "    spec_res_df.loc[count, 'model'] = one_biomd\n",
    "    spec_res_df.loc[count, 'species_id'] = one_spec\n",
    "    spec_name = species_an.model.getSpecies(one_spec).name\n",
    "    if len(spec_name) > 0:\n",
    "      spec_name_used = spec_name\n",
    "    else:\n",
    "      spec_name_used = one_spec\n",
    "    spec_res_df.loc[count, 'name_used'] = spec_name_used\n",
    "    spec_res_df.loc[count, 'name_length'] = len(spec_name_used)\n",
    "    spec_res_df.loc[count, 'num_candidates'] = len(species_an.candidates[one_spec])\n",
    "    spec_res_df.loc[count, 'match_score'] = species_an.match_score[one_spec]\n",
    "    predicted = species_an.formula[one_spec]\n",
    "    referenced = [ref_shortened_chebi_to_formula[val] \\\n",
    "                  for val in model_itm[one_spec]]\n",
    "    if any(set(referenced).intersection(predicted)):\n",
    "      spec_res_df.loc[count, 'accuracy'] = 1\n",
    "    else:\n",
    "      spec_res_df.loc[count, 'accuracy'] = 0\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "905066d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>species_id</th>\n",
       "      <th>name_used</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_candidates</th>\n",
       "      <th>match_score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>BIOMD0000000177.xml</td>\n",
       "      <td>EtOH</td>\n",
       "      <td>EtOH</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>BIOMD0000000177.xml</td>\n",
       "      <td>Glycerol</td>\n",
       "      <td>Glycerol</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>BIOMD0000000177.xml</td>\n",
       "      <td>Trehalose</td>\n",
       "      <td>Trehalose</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>BIOMD0000000177.xml</td>\n",
       "      <td>Succinate</td>\n",
       "      <td>Succinate</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>BIOMD0000000177.xml</td>\n",
       "      <td>CO2mito</td>\n",
       "      <td>CO2mito</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model species_id  name_used  name_length  num_candidates  \\\n",
       "4897  BIOMD0000000177.xml       EtOH       EtOH            4               1   \n",
       "4898  BIOMD0000000177.xml   Glycerol   Glycerol            8               1   \n",
       "4899  BIOMD0000000177.xml  Trehalose  Trehalose            9               2   \n",
       "4900  BIOMD0000000177.xml  Succinate  Succinate            9               1   \n",
       "4901  BIOMD0000000177.xml    CO2mito    CO2mito            7               7   \n",
       "\n",
       "      match_score  accuracy  \n",
       "4897     1.000000         1  \n",
       "4898     1.000000         1  \n",
       "4899     1.000000         1  \n",
       "4900     1.000000         1  \n",
       "4901     0.571429         0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_res_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7cbc1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_res_df.to_csv('individual_species_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60ddaf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_res_df.to_csv('individual_species_accuracy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35565db",
   "metadata": {},
   "source": [
    "# Next step will be to construct two (species & reactions, respectively) regression models to predict accuracy;; :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a161f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b48c0a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7876376988984088\n"
     ]
    }
   ],
   "source": [
    "# First, regresison model for species\n",
    "X = spec_res_df[['name_length', 'num_candidates', 'match_score']]\n",
    "y = spec_res_df['accuracy']\n",
    "clf = LogisticRegressionCV(cv=10, random_state=0, class_weight='balanced').fit(X, y)\n",
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94f24d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4902, 7)\n",
      "3641\n"
     ]
    }
   ],
   "source": [
    "print(spec_res_df.shape)\n",
    "print(np.sum(spec_res_df['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9ca288e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36818348, 0.63181652],\n",
       "       [0.36760611, 0.63239389],\n",
       "       [0.36760611, 0.63239389],\n",
       "       [0.37837246, 0.62162754],\n",
       "       [0.77636439, 0.22363561],\n",
       "       [0.35925305, 0.64074695],\n",
       "       [0.70364392, 0.29635608],\n",
       "       [0.36760611, 0.63239389],\n",
       "       [0.35925305, 0.64074695],\n",
       "       [0.33030819, 0.66969181],\n",
       "       [0.57380944, 0.42619056]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X.loc[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48fc9355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X.loc[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8494774c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36818348 0.63181652]\n",
      " [0.36760611 0.63239389]\n",
      " [0.36760611 0.63239389]\n",
      " [0.37837246 0.62162754]\n",
      " [0.77636439 0.22363561]\n",
      " [0.35925305 0.64074695]\n",
      " [0.70364392 0.29635608]\n",
      " [0.36760611 0.63239389]\n",
      " [0.35925305 0.64074695]\n",
      " [0.33030819 0.66969181]\n",
      " [0.57380944 0.42619056]]\n"
     ]
    }
   ],
   "source": [
    "# save fitted ML object\n",
    "filename_spec_res_cv = 'trained_cv_species.sav'\n",
    "# pickle.dump(clf, open(filename_spec_res_cv, 'wb'))\n",
    "\n",
    "# Test if saving was done correctly\n",
    "loaded_model = pickle.load(open(filename_spec_res_cv, 'rb'))\n",
    "result = loaded_model.predict_proba(X.loc[:10, :])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "50fb47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_biomd = list(chebi_models.keys())[0]\n",
    "one_biomd_fpath = os.path.join(BIOMODEL_DIR, one_biomd)\n",
    "species_an = sa.SpeciesAnnotation(libsbml_fpath=one_biomd_fpath)\n",
    "model_itm = chebi_models[one_biomd]\n",
    "pred_species = species_an.predictAnnotationByName(inp_spec_list=list(model_itm.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d68f172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATP': ['CHEBI:15422', 'CHEBI:30616'],\n",
       " 'ADP': ['CHEBI:16761', 'CHEBI:456216', 'CHEBI:73342'],\n",
       " 'AMP': ['CHEBI:16027', 'CHEBI:28971', 'CHEBI:456215']}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_an.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "149e9aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 2., 1.],\n",
       "       [3., 3., 1.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(data2prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a0751443",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = ['ATP', 'ADP']\n",
    "name_lengths = [len(getName(inp_id=val)) for val in specs]\n",
    "nums_candidates = [len(species_an.candidates[val]) for val in specs]\n",
    "match_scores = [species_an.match_score[val] for val in specs]\n",
    "data2prediction = list(zip(name_lengths, nums_candidates, match_scores))\n",
    "res_preds = loaded_model.predict_proba(data2prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5e70e7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36818348, 0.63181652],\n",
       "       [0.36760611, 0.63239389]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ef4fc737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ATP', 0.631816517626513), ('ADP', 0.6323938919261204)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(specs, [val[1] for val in res_preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa9cb58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNameToUse(inp_id):\n",
    "  \"\"\"\n",
    "  Get name to use;\n",
    "  If .name is not '', use it;\n",
    "  otherwise use ID\n",
    "  \n",
    "  Parameters\n",
    "  ----------\n",
    "  inp_id: ID of model element\n",
    "  \n",
    "  Returns\n",
    "  -------\n",
    "  res_name: str\n",
    "  \"\"\"\n",
    "  one_species = species_an.model.getSpecies(inp_id)\n",
    "  species_name = one_species.name\n",
    "  if len(species_name) > 0:\n",
    "    res_name = species_name\n",
    "  else:\n",
    "    res_name = inp_id\n",
    "  return res_name\n",
    "# Develop a method to evaluate results using fitted model\n",
    "def evaluatePredictedSpeciesAnnotation(inp_list, fitted_model=loaded_model):\n",
    "  \"\"\"\n",
    "  Evaluate the quality of annotation;\n",
    "  for each individual species.\n",
    "  \n",
    "  Parameters\n",
    "  ---------\n",
    "  inp_list: str-list?\n",
    "      List of species to evaluate (one or more)\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  res: dict {species_id: probability-of-species-prediction-being-correct}\n",
    "      Information of whether confident or not\n",
    "  \"\"\"\n",
    "  name_lengths = [len(getNameToUse(inp_id=val)) for val in inp_list]\n",
    "  nums_candidates = [len(species_an.candidates[val]) for val in inp_list]\n",
    "  match_scores = [species_an.match_score[val] for val in inp_list]\n",
    "  data2prediction = list(zip(name_lengths, nums_candidates, match_scores))\n",
    "  # loaded_model is loaded fitted logistic regression CV model\n",
    "  pred_probs = [val[1] for val in fitted_model.predict_proba(data2prediction)]\n",
    "  # Collect probability to be correct\n",
    "  res = {val[0]:val[1] for val in list(zip(inp_list, pred_probs))}\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "63f130cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATP': 0.631816517626513, 'ADP': 0.6323938919261204}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatePredictedSpeciesAnnotation(inp_list=['ATP', 'ADP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df0eec69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.505515\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# re-run using statsmodels;\n",
    "import statsmodels.api as sm\n",
    "X = spec_res_df[['name_length', 'num_candidates', 'match_score']]\n",
    "y = spec_res_df['accuracy']\n",
    "log_reg = sm.Logit(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddbe5722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               accuracy   No. Observations:                 4902\n",
      "Model:                          Logit   Df Residuals:                     4899\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Thu, 01 Sep 2022   Pseudo R-squ.:                  0.1134\n",
      "Time:                        15:02:29   Log-Likelihood:                -2478.0\n",
      "converged:                       True   LL-Null:                       -2794.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.476e-138\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "name_length        0.0088      0.002      3.531      0.000       0.004       0.014\n",
      "num_candidates    -0.0154      0.003     -5.221      0.000      -0.021      -0.010\n",
      "match_score        1.5267      0.061     24.953      0.000       1.407       1.647\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "972bc8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>reaction_id</th>\n",
       "      <th>num_candidates</th>\n",
       "      <th>mean_match_score</th>\n",
       "      <th>var_match_score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIOMD0000000152.xml</td>\n",
       "      <td>vcat1</td>\n",
       "      <td>65</td>\n",
       "      <td>0.250263</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIOMD0000000152.xml</td>\n",
       "      <td>vcat2</td>\n",
       "      <td>53</td>\n",
       "      <td>0.233109</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIOMD0000000152.xml</td>\n",
       "      <td>vcat3</td>\n",
       "      <td>54</td>\n",
       "      <td>0.360273</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIOMD0000000152.xml</td>\n",
       "      <td>vcat4</td>\n",
       "      <td>89</td>\n",
       "      <td>0.258619</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIOMD0000000152.xml</td>\n",
       "      <td>vcat5</td>\n",
       "      <td>188</td>\n",
       "      <td>0.214104</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model reaction_id  num_candidates  mean_match_score  \\\n",
       "0  BIOMD0000000152.xml       vcat1              65          0.250263   \n",
       "1  BIOMD0000000152.xml       vcat2              53          0.233109   \n",
       "2  BIOMD0000000152.xml       vcat3              54          0.360273   \n",
       "3  BIOMD0000000152.xml       vcat4              89          0.258619   \n",
       "4  BIOMD0000000152.xml       vcat5             188          0.214104   \n",
       "\n",
       "   var_match_score  accuracy  \n",
       "0         0.022159         0  \n",
       "1         0.015749         0  \n",
       "2         0.007730         0  \n",
       "3         0.024271         0  \n",
       "4         0.009476         0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reac_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "65f7b0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6951553930530164\n"
     ]
    }
   ],
   "source": [
    "# Second, regresison model for reactions\n",
    "X = reac_res_df[['num_candidates', 'mean_match_score']]\n",
    "y = reac_res_df['accuracy']\n",
    "clf = LogisticRegressionCV(cv=10, random_state=0, class_weight='balanced').fit(X, y)\n",
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938697ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability\n",
    "clf.predict_proba(X.loc[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3f1c3a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.619364\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               accuracy   No. Observations:                 2188\n",
      "Model:                          Logit   Df Residuals:                     2185\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Fri, 02 Sep 2022   Pseudo R-squ.:                 0.06873\n",
      "Time:                        16:36:38   Log-Likelihood:                -1355.2\n",
      "converged:                       True   LL-Null:                       -1455.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.663e-44\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "num_candidates       0.0002   6.42e-05      2.736      0.006    4.98e-05       0.000\n",
      "mean_match_score     1.3109      0.083     15.823      0.000       1.148       1.473\n",
      "var_match_score     -4.2751      2.408     -1.775      0.076      -8.996       0.445\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# re-run using statsmodels;\n",
    "import statsmodels.api as sm\n",
    "X = reac_res_df[['num_candidates', 'mean_match_score', 'var_match_score']]\n",
    "y = reac_res_df['accuracy']\n",
    "log_reg = sm.Logit(y, X).fit()\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bde13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop a method to evaluate results using fitted model\n",
    "def evaluatePredictedReactionAnnotation(inp_list):\n",
    "  \"\"\"\n",
    "  Evaluate the quality of annotation;\n",
    "  for each individual species.\n",
    "  \n",
    "  Parameters\n",
    "  ---------\n",
    "  inp_list: str-list?\n",
    "      List of reactions to evaluate (one or more)\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  res: dict {reaction_id: probability-of-species-prediction-being-correct}\n",
    "      Information of whether confident or not\n",
    "  \"\"\"\n",
    "\n",
    "  nums_candidates = [len(reaction_an.candidates[val]) for val in inp_list]\n",
    "  max_matches = []\n",
    "  mean_match_scores = []\n",
    "  data2prediction = list(zip(nums_candidates, max_matches, mean_match_scores))\n",
    "  # loaded_model is loaded fitted logistic regression CV model\n",
    "  pred_probs = [val[1] for val in loaded_model.predict_proba(data2prediction)]\n",
    "  # Collect probability to be correct\n",
    "  res = {val[0]:val[1] for val in list(zip(inp_list, pred_probs))}\n",
    "  return res\n",
    "\n",
    "  name_lengths = [len(getNameToUse(inp_id=val)) for val in specs]\n",
    "  nums_candidates = [len(species_an.candidates[val]) for val in specs]\n",
    "  match_scores = [species_an.match_score[val] for val in specs]\n",
    "  data2prediction = list(zip(name_lengths, nums_candidates, match_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyo",
   "language": "python",
   "name": "pyo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
